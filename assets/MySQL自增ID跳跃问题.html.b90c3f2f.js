const t=JSON.parse('{"key":"v-4fc7a1e0","path":"/codenotes/database/MySQL/MySQL%E8%87%AA%E5%A2%9EID%E8%B7%B3%E8%B7%83%E9%97%AE%E9%A2%98.html","title":"MySQL自增ID跳跃问题","lang":"zh-CN","frontmatter":{"title":"MySQL自增ID跳跃问题","icon":"storage","category":["MySQL"],"tag":["MySQL"],"sticky":false,"star":26,"article":true,"timeline":true,"description":"记一次MySQL自增ID发生跳跃的问题 在对大规模数据进行分页查询测试性能时，我使用了MySQL的蠕虫复制快速生成了百万级别的数据，但是发现了一个很奇怪的问题，先回顾一下我的操作： emp表中有13条记录，此时再创建一个新表test作为测试表，并从emp表中查询数据插入到测试表中： 此时测试表test中也有了13条记录 接下来进行蠕虫复制，反复执行如下...","head":[["meta",{"property":"og:url","content":"http://www.codepit.tech/mynotes/mynotes/codenotes/database/MySQL/MySQL%E8%87%AA%E5%A2%9EID%E8%B7%B3%E8%B7%83%E9%97%AE%E9%A2%98.html"}],["meta",{"property":"og:site_name","content":"Zuooの学习笔记"}],["meta",{"property":"og:title","content":"MySQL自增ID跳跃问题"}],["meta",{"property":"og:description","content":"记一次MySQL自增ID发生跳跃的问题 在对大规模数据进行分页查询测试性能时，我使用了MySQL的蠕虫复制快速生成了百万级别的数据，但是发现了一个很奇怪的问题，先回顾一下我的操作： emp表中有13条记录，此时再创建一个新表test作为测试表，并从emp表中查询数据插入到测试表中： 此时测试表test中也有了13条记录 接下来进行蠕虫复制，反复执行如下..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:updated_time","content":"2023-03-13T04:33:46.000Z"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:tag","content":"MySQL"}],["meta",{"property":"article:modified_time","content":"2023-03-13T04:33:46.000Z"}]]},"excerpt":"","headers":[{"level":2,"title":"记一次MySQL自增ID发生跳跃的问题","slug":"记一次mysql自增id发生跳跃的问题","link":"#记一次mysql自增id发生跳跃的问题","children":[]}],"git":{"createdTime":1678682026000,"updatedTime":1678682026000,"contributors":[{"name":"zql","email":"1241236275@qq.com","commits":1}]},"readingTime":{"minutes":6.75,"words":2024},"filePathRelative":"codenotes/database/MySQL/MySQL自增ID跳跃问题.md","localizedDate":"2023年3月13日"}');export{t as data};
