import{_ as i}from"./_plugin-vue_export-helper.cdc0426e.js";import{o as l,c as t,a,d as e,e as s,b as o,r as d}from"./app.7b0c1160.js";const r={},p=o('<h2 id="一、hadoop概述" tabindex="-1"><a class="header-anchor" href="#一、hadoop概述" aria-hidden="true">#</a> 一、Hadoop概述</h2><h3 id="_1-hadoop是什么" tabindex="-1"><a class="header-anchor" href="#_1-hadoop是什么" aria-hidden="true">#</a> 1.Hadoop是什么？</h3><p>Hadoop是一个开源的框架，使用Java开发，可编写和运行分布式应用处理大规模数据，是专为离线和大规模数据分析而设计的，支持在单台计算机到几千台计算机之间进行扩展，是一个分布式计算的解决方案</p><blockquote><p>The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage.</p></blockquote><p>Hadoop 在某种程度上将多台计算机组织成了一台计算机（做同一件事），那么 HDFS 就相当于这台计算机的硬盘，而 MapReduce 就是这台计算机的 CPU 控制器</p><p>Hadoop2.0生态系统架构图：</p><p><img src="https://s2.loli.net/2022/12/25/xV1JayoQrzpeh4l.png" alt="hadoop生态架构"></p><p>底层：存储层，文件系统HDFS，NoSQL Hbase</p><p>中间层：资源及数据管理层，YARN以及Sentry等</p><p>上层：MapReduce、Impala、Spark等计算引擎</p><p>顶层：基于MapReduce、Spark等计算引擎的高级封装及工具，如Hive、Pig、Mahout</p><h3 id="_2-使用场景" tabindex="-1"><a class="header-anchor" href="#_2-使用场景" aria-hidden="true">#</a> 2.使用场景</h3><ul><li>大数据量存储：分布式存储（各种云盘，百度，360~还有云平台均有hadoop应用）</li><li>日志处理: Hadoop擅长这个</li><li>海量计算: 并行计算</li><li>ETL:数据抽取到oracle、mysql、DB2、mongdb及主流数据库</li><li>使用HBase做数据分析: 用扩展性应对大量读写操作—Facebook构建了基于HBase的实时数据分析系统</li><li>机器学习: 比如Apache Mahout项目（Apache Mahout简介 常见领域：协作筛选、集群、归类）</li><li>搜索引擎:hadoop + lucene实现</li><li>数据挖掘：目前比较流行的广告推荐</li><li>大量地从文件中顺序读。HDFS对顺序读进行了优化，代价是对于随机的访问负载较高</li><li>用户行为特征建模</li><li>个性化广告推荐</li><li>智能仪器推荐</li></ul><h3 id="_3-hadoop发行版" tabindex="-1"><a class="header-anchor" href="#_3-hadoop发行版" aria-hidden="true">#</a> 3.Hadoop发行版</h3><ul><li>Apache Hadoop</li><li>Cloudera’s Distribution Including Apache Hadoop（CDH）</li><li>Hortonworks Data Platform (HDP)</li><li>MapR</li><li>EMR …</li></ul><hr><p>Apache Hadoop不足之处：</p><ol><li>版本管理混乱</li><li>部署过程繁琐、升级过程复杂</li><li>兼容性差</li><li>安全性低</li></ol><blockquote><p>Cloudera版本(CDH)</p></blockquote><ol><li>版本划分清晰</li><li>版本更新速度快</li><li>支持Kerberos安全认证</li><li>文档清晰</li><li>支持多种安装方式（Cloudera Manager方式）</li></ol><hr><blockquote><p>Hortonworks版本（HDP）</p></blockquote><p>区别于其他的Hadoop发行版(如Cloudera)的根本就在于，Hortonworks的产品均是百分之百开源</p><hr><blockquote><p>TDH(Transwarp Data Hub)</p></blockquote><p>TranswarpInceptor是星环科技推出的用于 <code>&lt;font color=red&gt;</code>数据仓库和交互式分析 <code>&lt;/font&gt;</code>的大数据平台软件，它基于Hadoop和Spark技术平台打造，加上自主开发的创新功能组件，有效的解决了企业级大数据数据处理和分析的各种技术难题，帮助企业快速的构建和推广数据业务。从2016年起，TDH正式成为Gartner认可的Hadoop国际主流发行版本</p><h3 id="_4-hadoop三种运行模式" tabindex="-1"><a class="header-anchor" href="#_4-hadoop三种运行模式" aria-hidden="true">#</a> 4.Hadoop三种运行模式</h3><ol><li><p>独立（本地）/单机运行模式：</p><blockquote><p>无需任何守护进程，所有的程序都运行在同一个JVM上执行。在独立模式下调试MR程序非常高效方便。所以一般该模式主要是在学习或者开发阶段调试使用 。</p></blockquote></li><li><p>伪分布式模式：</p><blockquote><p>Hadoop守护进程运行在本地机器上，模拟一个小规模的集群，换句话说，可以配置一台机器的Hadoop集群,单机上的分布式并不是真正的伪分布式，而是使用线程模拟分布式。hadoop本身是无法区分伪分布式和分布式的，两种配置也很相似。</p></blockquote></li><li><p>集群/完全分布式模式：</p><blockquote><p>Hadoop守护进程运行在一个集群上,由多个各司其职的节点构成</p></blockquote></li></ol><p>注：开发环境，使用独立模式；测试环境，可以使用伪分布式模式；线上生产环境，使用完全分布式模式</p><h2 id="二、docker搭建hadoop环境" tabindex="-1"><a class="header-anchor" href="#二、docker搭建hadoop环境" aria-hidden="true">#</a> 二、Docker搭建Hadoop环境</h2><p>软件：Oracle VM VirtualBox　Vagrant</p><p>操作系统：Centos7</p><p>下载地址：</p>',33),c={href:"https://www.virtualbox.org/",target:"_blank",rel:"noopener noreferrer"},u={href:"https://www.vagrantup.com/",target:"_blank",rel:"noopener noreferrer"},h=o(`<h3 id="_1-搭建linux平台" tabindex="-1"><a class="header-anchor" href="#_1-搭建linux平台" aria-hidden="true">#</a> 1.搭建Linux平台</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>vagrant init centos/7 <span class="token comment">#初始化安装系统信息</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="https://s2.loli.net/2022/12/25/RdItSfOTl3g92xJ.png" alt="001"></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>vagrant up	<span class="token comment">#下载镜像文件完成安装，会安装ssh工具，默认用户名vagrant</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="https://s2.loli.net/2022/12/25/RTNfarWuo4Ebksp.png" alt="002"></p><p>此时打开VirtualBox就可以看到正在运行的虚拟机了</p><p><strong>配置网络</strong></p><p>编辑vagrantfile使Windows主机与Linux互通</p><p><img src="https://s2.loli.net/2022/12/25/EqtfkdHOlnwLW5p.png" alt="003"></p><p><strong>重启Linux系统，使配置生效</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>vagrant reload <span class="token comment">#或者vagrant up</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><strong>登录Linux系统，查看ip地址</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>vagrant <span class="token function">ssh</span> 
<span class="token function">ip</span> addr
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p><img src="https://s2.loli.net/2022/12/25/iYMCxwaeHzyNnFk.png" alt="004"></p><h3 id="_2-安装docker" tabindex="-1"><a class="header-anchor" href="#_2-安装docker" aria-hidden="true">#</a> 2.安装docker</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sudo</span> yum remove <span class="token function">docker</span> <span class="token punctuation">\\</span>
docker-client <span class="token punctuation">\\</span>
docker-client-latest <span class="token punctuation">\\</span>
docker-common <span class="token punctuation">\\</span>
docker-latest <span class="token punctuation">\\</span>
docker-latest-logrotate <span class="token punctuation">\\</span>
docker-logrotate <span class="token punctuation">\\</span>
docker-engine

<span class="token function">sudo</span> yum <span class="token function">install</span> <span class="token parameter variable">-y</span> yum-utils

<span class="token function">sudo</span> yum-config-manager <span class="token punctuation">\\</span>
--add-repo <span class="token punctuation">\\</span>
https://download.docker.com/linux/centos/docker-ce.repo

<span class="token function">sudo</span> yum <span class="token function">install</span> docker-ce docker-ce-cli containerd.io

<span class="token function">sudo</span> systemctl start <span class="token function">docker</span>	  <span class="token comment">#启动docker</span>

<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> <span class="token function">docker</span>  <span class="token comment">#设置自启动</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可自行去阿里云控制台容器服务进行镜像加速配置</p><h3 id="_3-拉取镜像" tabindex="-1"><a class="header-anchor" href="#_3-拉取镜像" aria-hidden="true">#</a> 3.拉取镜像</h3><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sudo</span> <span class="token function">docker</span> pull kiwenlau/hadoop:1.0 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_4-克隆配置脚本" tabindex="-1"><a class="header-anchor" href="#_4-克隆配置脚本" aria-hidden="true">#</a> 4.克隆配置脚本</h3><p>从github上克隆配置脚本，脚本的内容是使用kiwenlau/hadoop:1.0配置mater、slave1、slave2三个容器，其中slave数量可以修改</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://github.com/kiwenlau/hadoop-cluster-docker
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>如果显示没有git，需要进行安装，sudo yum -y install git</p><h3 id="_5-创建网桥" tabindex="-1"><a class="header-anchor" href="#_5-创建网桥" aria-hidden="true">#</a> 5.创建网桥</h3><p>由于Hadoop的master节点需要与slave节点通信，需要在各个主机节点配置节点IP，为了不用每次启动都因为IP改变了而重新配置，在此配置一个Hadoop专用的网桥，配置之后各个容器的IP地址就能固定下来</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sudo</span> <span class="token function">docker</span> network create <span class="token parameter variable">--driver</span><span class="token operator">=</span>bridge hadoop
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="https://s2.loli.net/2022/12/25/MkAUyoxNcbgVr8J.png" alt="005"></p><h3 id="_6-执行脚本" tabindex="-1"><a class="header-anchor" href="#_6-执行脚本" aria-hidden="true">#</a> 6.执行脚本</h3><p>通过前面步骤克隆下来的脚本进行容器创建</p><p>查看脚本内容：</p><p><img src="https://s2.loli.net/2022/12/25/R5JA8vsFo1DMOgw.png" alt="006"></p><p>为了后续通过IDEA连接，需要修改脚本，添加一个端口映射，将容器的9000端口映射到本地的9000端口，在-p 8088:8088 \\下添加一行如下图所示</p><p><img src="https://s2.loli.net/2022/12/25/dxcbg6eD5oRWMjG.png" alt="007"></p><p>执行脚本，脚本在创建完容器之后进入了<strong>容器终端</strong></p><p><img src="https://s2.loli.net/2022/12/25/Zkm3NuELHzXoC1R.png" alt="008"></p><h3 id="_7-安装vim" tabindex="-1"><a class="header-anchor" href="#_7-安装vim" aria-hidden="true">#</a> 7.安装vim</h3><p>由于kiwenlau/hadoop:1.0这个镜像没有安装vim编辑器，因此需要先把vim装上</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token function">vim</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_8-启动hadoop" tabindex="-1"><a class="header-anchor" href="#_8-启动hadoop" aria-hidden="true">#</a> 8.启动hadoop</h3><p>在前面一个步骤的最后进入了Hadoop容器的终端(master节点)，因为是已经配置好Hadoop的容器，所以可以直接使用Hadoop，在容器根目录下有一个启动Hadoop的脚本，脚本代码如下，启动了dfs和yarn：</p><p><img src="https://s2.loli.net/2022/12/25/nPdY26z9gBVHZjX.png" alt="009"></p><p><img src="https://s2.loli.net/2022/12/25/5ptmhAkNq8SYMKW.png" alt="010"></p><h3 id="_9-测试wordcount" tabindex="-1"><a class="header-anchor" href="#_9-测试wordcount" aria-hidden="true">#</a> 9.测试wordcount</h3><p>根目录下还有一个测试WordCount程序的脚本，WordCount是Hadoop里“Hello World”程序，是一个用于文本字符统计的MapReduce程序，先来看一下run-wordcount.sh这个脚本的内容，脚本往hdfs里添加了数据文件，然后执行了Hadoop里的例子hadoop-mapreduce-examples-2.7.2-sources.jar： <img src="https://s2.loli.net/2022/12/25/slvChe8DmGwZaHj.png" alt="011"></p><p>执行脚本：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>./run-wordcount.sh
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p><img src="https://s2.loli.net/2022/12/25/leoOmf9N28Lt5QF.png" alt="012"></p><h3 id="_10-查看web页面" tabindex="-1"><a class="header-anchor" href="#_10-查看web页面" aria-hidden="true">#</a> 10.查看web页面</h3><p><code>&lt;u&gt;</code><em><strong>Name Node</strong></em> <code>&lt;/u&gt;</code></p>`,49),m={href:"http://192.168.56.130:50070/",target:"_blank",rel:"noopener noreferrer"},g=a("ul",null,[a("li",null,"进入页面可以看到各节点的情况，注意如果Summary下的节点信息异常(容量为0、Live Nodes为0等)可能是配置过程出现了问题。"),a("li",null,"在导航栏的Utilities中有两个选项Browse the file system和Logs，前者是查看hdfs文件系统的，后者是查看Hadoop运行日志的，出现任何异常时可以在日志中查看，看能否找出异常原因。")],-1),v=a("p",null,[a("img",{src:"https://s2.loli.net/2022/12/25/TPgvK8aQxG4zUch.png",alt:"013"})],-1),b=a("p",null,[a("strong",null,[a("code",null,"<u>"),a("em",null,"Resource Manager"),e(),a("code",null,"</u>")])],-1),k={href:"http://192.168.56.130:8088/",target:"_blank",rel:"noopener noreferrer"},f=a("p",null,[a("img",{src:"https://s2.loli.net/2022/12/25/L8nijwcXt7J3GhO.png",alt:"014"})],-1),_=a("hr",null,null,-1),H=a("h2",{id:"三、学习参考资料",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#三、学习参考资料","aria-hidden":"true"},"#"),e(" 三、学习参考资料")],-1),x={href:"https://chu888chu888.gitbooks.io/hadoopstudy/content/",target:"_blank",rel:"noopener noreferrer"};function w(y,M){const n=d("ExternalLinkIcon");return l(),t("div",null,[p,a("p",null,[a("strong",null,[a("a",c,[e("https://www.virtualbox.org/"),s(n)])])]),a("p",null,[a("strong",null,[a("a",u,[e("https://www.vagrantup.com/"),s(n)])])]),h,a("p",null,[e("打开本地浏览器访问："),a("a",m,[e("http://192.168.56.130:50070/"),s(n)]),e(" 【这里的ip地址是之前在vagrantfile里面进行配置的】")]),g,v,b,a("p",null,[e("打开本地浏览器访问："),a("a",k,[e("http://192.168.56.130:8088/"),s(n)]),e(" ,可以查看Hadoop 应用及执行情况")]),f,_,H,a("p",null,[a("a",x,[e("大数据学习笔记 (gitbooks.io)"),s(n)])])])}const N=i(r,[["render",w],["__file","hadoop.html.vue"]]);export{N as default};
